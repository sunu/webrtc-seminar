<!--
WebRTC: Pluginless Realtime Communication for the Web

Author: Tarashish Mishra<tarashishmishra@gmail.com>

URL: https://sunu.in/talks/webrtc-slides
-->
<!DOCTYPE html>
<html>
<head>
  <title></title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="logoslide nobackground">
    <article class="flexbox vcenter">
      <span><img src="images/webrtc_logo.png"></span>
    </article>
  </slide>

  <slide class="title-slide segue nobackground">
    <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
    <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
    </hgroup>
  </slide>

  <slide class="segue dark nobackground">
    <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
    <hgroup class="auto-fadein">
      <h2>What is WebRTC?</h2>
    </hgroup>
  </slide>

  <slide>
    <article class="vcenter">
      <h3>
        "WebRTC is a free, open project that enables web browsers with Real-Time Communications (RTC) capabilities via simple JavaScript APIs without the
        use of external native plugins."
      </h3>
      <br>
      <br>
      <p>It has three main functions:</p>
      <br>
      <ul class="build">
        <li>Access and acquire video and audio streams</li>
        <li>Establish a connection between peers and stream audio/video.</li>
        <li>Communicate arbitrary data.</li>
      </ul>  
    </article>
  </slide>

  <slide class="segue dark nobackground">
    <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
    <hgroup class="auto-fadein">
      <h2>Why WebRTC?</h2>
    </hgroup>
  </slide>

  <slide>
    <article class="">
      <p>Let us take a look at various advantages that WebRTC offers compared to existing technologies:</p>
      <br>
      <ul class="build">
        <li>Proprietary <img src="images/no.png"></li>
        <li>OpenSource <img src="images/yes.png"></li>
        <li>Plugins <img src="images/no.png"></li>
        <li>Built into the browser <img src="images/yes.png"></li>
        <li>Centralised <img src="images/no.png"></li>
        <li>Peer to Peer <img src="images/yes.png"></li>
        <li>Snooping <img src="images/no.png"></li>
        <li>Privacy <img src="images/yes.png"></li>
        <li>Platform Dependent <img src="images/no.png"></li>
        <li>Cross platform <img src="images/yes.png"></li>
      </ul>  
    </article>
  </slide>

  <slide class="segue dark nobackground">
    <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
    <hgroup class="auto-fadein">
      <h2>How WebRTC works?</h2>
    </hgroup>
  </slide>

  <slide>
    <article class="vcenter">
      <p>As you may recall, WebRTC has three main functions:</p>
      <br>
      <ul class="build">
        <li>Access and acquire video and audio streams</li>
        <li>Establish a connection between peers and stream audio/video.</li>
        <li>Communicate arbitrary data.</li>
      </ul>  
    </article>
  </slide>

  <slide>
    <article class="vcenter">
      <p>It has 3 Javascript APIs to perform these 3 functions:</p>
      <br>
      <ul class="build">
        <li>MediaStream (aka getUserMedia) - Access and acquire video and audio streams</li>
        <li>RTCPeerConnection - Establish a connection between peers and stream audio/video.</li>
        <li>RTCDataChannel - Communicate arbitrary data.</li>
      </ul>  
    </article>
  </slide>

  <slide class="segue dark nobackground">
    <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
    <hgroup class="auto-fadein">
      <h2>MediaStream</h2>
      <h3>Acquiring audio and video</h3>
    </hgroup>
    <aside class="note">
    </aside>
  </slide>

  <slide>
    <hgroup>
      <h2>MediaStream</h2>
    </hgroup>
    <article>
      <ul>
        <li>Represents a stream of audio and/or video</li>
        <li>Can contain multiple 'tracks'</li>
        <li>Obtain a MediaStream with <code>navigator.getUserMedia()</code></li>
      </ul>
      <img src="images/mediaStream.png" alt="MediaStream diagram" style="width: 550px" />
    </article>
    <aside class="note">
    </aside>
  </slide>

  <!-- <slide class="nobackground">
    <article class="flexbox vcenter">
      <img src="images/mediaStream.png" alt="MediaStream diagram" style="width: 733px" />
    </article>
    </article>
    <aside class="note">
    </aside>
  </slide> -->

  <slide>
    <hgroup>
      <h2>MediaStream</h2>
      <h3>aka getUserMedia</h3>
    </hgroup>
    <article>
      <pre class="prettyprint" data-lang="javascript">
  var constraints = {video: true};

  function successCallback(stream) {
    var video = document.querySelector("video");
    video.src = window.URL.createObjectURL(stream);
  }

  function errorCallback(error) {
    console.log("navigator.getUserMedia error: ", error);
  }

  <b>navigator.getUserMedia(constraints, successCallback, errorCallback);</b>
  </pre>
    </article>
  </slide>

  <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="bigger"><a href="http://localhost:8000/gum" title="Simple getUserMedia demo">Demo Time</a></div>
    </article>
  </slide>

  <slide class="nobackground">
      <article class="fill flexbox vcenter">
        <div><a href="http://idevelop.github.com/ascii-camera/" title="getUserMedia video rendered as ASCII art">idevelop.github.com/ascii-camera</a></div>
      </article>
      <aside class="note">
      </aside>
  </slide>

  <slide class="nobackground">
      <article class="fill flexbox vcenter">
        <div><a href="http://www.shinydemos.com/facekat/" title="getUserMedia used to control a game">FaceKat</a></div>
      </article>
      <aside class="note">
      </aside>
  </slide>

  <slide class="nobackground">
      <article class="fill flexbox vcenter">
        <div><a href="http://webcamtoy.com/app" title="getUserMedia photobooth, with effects">webcamtoy.com</a></div>
      </article>
      <aside class="note">
      </aside>
  </slide>

  <slide>
    <hgroup>
      <h2>Constraints</h2>
    </hgroup>
    <article>
      <ul>
        <li>Controls the contents of the MediaStream</li>
        <li>Media type, resolution, frame rate</li>
      </ul>
      <pre class="prettyprint" data-lang="javascript">
  video: {
    mandatory: {
      minWidth: 640,
      minHeight: 360
    },
    optional [{
      minWidth: 1280,
      minHeight: 720
    }]
  }
   </pre>
    </article>
  </slide>

  <slide>
  <hgroup>
    <h2>getUserMedia + Web Audio</h2>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
// Success callback when requesting audio input stream
function gotStream(stream) {
    var audioContext = new webkitAudioContext();

    // Create an AudioNode from the stream
    var mediaStreamSource = audioContext.createMediaStreamSource(stream);

    // Connect it to the destination or any other node for processing!
    mediaStreamSource.connect(audioContext.destination);
}

navigator.webkitGetUserMedia({audio:true}, gotStream);
</pre>
  </article>
</slide>

 <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://localhost:8000/audio" title="Record audio">Demo time again!</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>RTCPeerConnection</h2>
    <h3>Audio and video communication between peers</h3>
  </hgroup>
  <aside class="note">
    <p>This is the API for audio and video communication, to create a connection between peers.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Communicate Media Streams</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <div>
      <img style="float: left; width: 27%;" src="images/caller.jpg" alt="WebRTC video chat: caller" />
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; text-align: center;">
      →<br />
      getUserMedia<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>
      <img  style="float: left; position: relative; top: 38px; width: 35%;" src="images/callee.jpg" alt="WebRTC video chat: callee" />
    </div>
  </article>
  <aside class="note">
    On the surface, the API is simple - get access to MediaStreams via getUserMedia, then plug them into a PeerConnection, and they will get sent to another WebRTC endpoint automatically. And when we receive media from the remote side, this goes into new MediaStreams that can be rendered in our web page.
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>RTCPeerConnection does a lot</h2>
  </hgroup>
    <article>
  <ul>
    <li>Signal processing</li>
    <li>Codec handling</li>
    <li>Peer to peer communication</li>
    <li>Security</li>
    <li>Bandwidth management</li>
  </ul>
    <p>...</p>
    </article>
    <aside class="note">
    <p>Under the hood though, RTCPeerConnection is doing a lot - processing audio and video to remove noise, compressing the data using codecs, setting up the peer to peer pathway through NATs and firewalls, encrypting the data, ensuring we use the right amount of bandwidth...</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>WebRTC architecture</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/webrtcArchitecture.png" alt="WebRTC architecture diagram" />
  </article>
  <aside class="note">
  <p>There's a lot of moving parts under the hood. Fortunately, with RTCPeerConnection, this is mostly abstracted away. You create a RTCPeerConnection, add your own MediaStreams to it, call a couple methods to set up the right parameters for the call, and off you go. Sam's going to now show us a super-simple example of RTCPeerConnection.'
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>RTCPeerConnection sample</h2>
      </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
pc = new RTCPeerConnection(null);
pc.onaddstream = gotRemoteStream;
pc.addStream(localStream);
pc.createOffer(gotOffer);

function gotOffer(desc) {
  pc.setLocalDescription(desc);
  sendOffer(desc);
}

function gotAnswer(desc) {
  pc.setRemoteDescription(desc);
}

function gotRemoteStream(e) {
  attachMediaStream(remoteVideo, e.stream);
}
</pre>
  </article>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big"><a href="http://www.simpl.info/pc" title="Simple one-page RTCPeerConnection example">simpl.info/pc</a></div>
    </article>
    <aside class="note">
      <p>If you want to understand how WebRTC works, it's good to learn about RTCPeerConnection first, before you try to get your head around signaling mechanisms.</p>
      <p>This 'single page' demo does just that.</p>
      <p>It's very verbose: take a look at the console.</p>
      <p>Also take a look at chrome://webrtc-internals.</p>
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>RTCDataChannel</h2>
    <h3>Bidirectional communication of arbitrary data between peers</h3>
  </hgroup>
  <aside class="note">
    <p>The last API to talk about is RTCDataChannel.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Communicate arbitrary data</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
  <div>

  <div style="float: left; width: 28%;">
    <img style="display: block; margin: 0 0 0.5em 0; position: relative; width: 100%;" src="images/jankInvadersScreenshot.jpg" alt="Game: caller" />
    <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship1";
    x: 24,
    y: 11,
    velocity: 7
  },
  ....
]
send(myData);
</div>
      </div>
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; position: relative; text-align: center; top: 4em; width: 25%;">
      →<br />
      RTCDataChannel<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>

      <div style="float: left; width: 28%;">
        <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; margin: 0 0 1em 0; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship7";
    x: 19,
    y: 4,
    velocity: 18
  },
  ....
]
send(myData);
</div>
        <img style="display: block; width: 100%;" src="images/jankInvadersScreenshotReversed.jpg" alt="Game: callee" />
      </div>

  </div>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>RTCDataChannel</h2>
  </hgroup>
  <article>
    <ul>
      <li>Same API as WebSockets</li>
      <li>Ultra-low latency</li>
      <li>Unreliable or reliable</li>
      <li>Secure</li>
    </ul>
  </article>
    <aside class="note">
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Servers and Protocols</h2>
    <h3>Peer to peer &mdash; but we need servers  :^\</h3>
  </hgroup>
  <aside class="note">
      <p>So we just talked about how WebRTC can do all sorts of clever peer-to-peer stuff. But in order to bring up the peer-to-peer connection, we need servers to help coordinate things.
      The first thing we need to do is something we call signaling.</p>
  </aside>
</slide>
<!--
<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div>Peer to peer &mdash; but we need servers  :^\</div>
    </article>
    <aside class="note">
      <p>So discovery and signaling require intermediary servers to set up a call.</p>
      <p>At this point in history there's no way to say 'Exchange streaming data with my friend's computer!'</p>
    </aside>
</slide>
-->
<!-- <slide class="nobackground">
  <hgroup>
    <h2>Peer discovery</h2>
  </hgroup>
  <article>
    <ul>
      <li>Find peers (WebRTC clients)</li>
      <li>Coordinate communication</li>
    </ul>
  </article>
  <aside class="note">
    <p>This is the process of making contact with someone in order to begin communicating with them.</p>
    <p>If you use the telephone, you need a phone number -- and in terms of telephony, mechanisms to set up a call. </p>
    <p>Likewise for using chat on your computer. WebRTC is similar.</p>
    <p>A really simple example of a discovery mechanism is to share a URL. That's what's been done on several of the WebRTC demos. You can share the URL, then via a server establish some kind of communication channel.</p>
    <p>Just to reiterate: WebRTC does not specify how to do this.</p>
  </aside>
</slide> -->

<slide class="nobackground">
  <hgroup>
    <h2>Abstract Signaling</h2>
  </hgroup>
  <article>
    <ul>
      <li>Need to exchange 'session description' objects:</li>
      <ul class="tight">
      <li>What formats I support, what I want to send</li>
      <li>Network information for peer-to-peer setup</li>
      </ul>
      <li>Can use any messaging mechanism</li>
      <li>Can use any messaging protocol</li>
    </ul>
  </article>
  <aside class="note">
    <p>Signalling is the process of coordinating communication. Similar to, when you make a phone call, the phone system sends a message to the person you're calling indicating that there's an incoming call. Then, when you answer the call, a message is sent back indicating the call is live.</p>
    <p>The same is true for WebRTC. A message needs to get sent by each side indicating the parameters they want to use for the call. This is called a "session description", and it includes a bunch of details regarding codecs, encryption, network information, etc.</p>
    <p>The details aren't critical for most apps; they just need to exchange these messages in some way. The mechanism is up to the app - it can use WebSockets, Google Cloud Messaging, XHR, whatever it wants to use.</p>
    <p>Similarly, the exact protocol through which these are exchanged is also up to the app - many apps will send these messages as JSON, although some apps may use the standard SIP or XMPP protocols.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Signaling Diagram</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/jsep.png" alt="JSEP architecture diagram">
  </article>
      <aside class="note">
      <p>Here's a diagram that demonstrates this process. The caller sends a session description to its signaling server in the cloud, which then forwards this on to the callee. Similarly, the callee then sends its own session description back through the cloud to the caller. Once each side has given the session descriptions to RTCPeerConnection, the peer-to-peer link is established and media can flow.</p>
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Servers and Protocols</h2>
    <h3>Peer to peer &mdash; but we need servers  :^\</h3>
  </hgroup>
  <aside class="note">
      <p>So we just talked about how WebRTC can do all sorts of clever peer-to-peer stuff. But in order to bring up the peer-to-peer connection, we need servers to help coordinate things.
      The first thing we need to do is something we call signaling.</p>
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>Abstract Signaling</h2>
  </hgroup>
  <article>
    <ul>
      <li>Need to exchange 'session description' objects:</li>
      <ul class="tight">
      <li>What formats I support, what I want to send</li>
      <li>Network information for peer-to-peer setup</li>
      </ul>
      <li>Can use any messaging mechanism</li>
      <li>Can use any messaging protocol</li>
    </ul>
  </article>
  <aside class="note">
    <p>Signalling is the process of coordinating communication. Similar to, when you make a phone call, the phone system sends a message to the person you're calling indicating that there's an incoming call. Then, when you answer the call, a message is sent back indicating the call is live.</p>
    <p>The same is true for WebRTC. A message needs to get sent by each side indicating the parameters they want to use for the call. This is called a "session description", and it includes a bunch of details regarding codecs, encryption, network information, etc.</p>
    <p>The details aren't critical for most apps; they just need to exchange these messages in some way. The mechanism is up to the app - it can use WebSockets, Google Cloud Messaging, XHR, whatever it wants to use.</p>
    <p>Similarly, the exact protocol through which these are exchanged is also up to the app - many apps will send these messages as JSON, although some apps may use the standard SIP or XMPP protocols.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Signaling Diagram</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/jsep.png" alt="JSEP architecture diagram">
  </article>
      <aside class="note">
      <p>Here's a diagram that demonstrates this process. The caller sends a session description to its signaling server in the cloud, which then forwards this on to the callee. Similarly, the callee then sends its own session description back through the cloud to the caller. Once each side has given the session descriptions to RTCPeerConnection, the peer-to-peer link is established and media can flow.</p>
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>STUN and TURN</h2>
    <h3>P2P in the age of firewalls and NATs</h3>
  </hgroup>
  <aside class="note">
      <p>The other place where servers come into play is in figuring out how to route the peer-to-peer connection.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>An ideal world</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/noSTUNorTURN.png" alt="Data pathways between peers if there were no NATs or firewalls" style="position: relative; top: -30px">
  </article>
    <aside class="note">
      <p>In an ideal world, life would be simple - each endpoint could tell the other side its IP address, and a direct link could easily be established.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>The real world</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/firewall.png" alt="Data pathways showing firewalls" style="position: relative; top: -26px">

  </article>
   <aside class="note">
   <p>But in the age of NAT, this just isn't the case. Most users are behind what's called a NAT, which hands out a private IP address that can't be used for communication. Without a public address, there's no way to set up a peer-to-peer link.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>STUN</h2>
  </hgroup>
  <article>
    <ul>
      <li>Tell me what my public IP address is</li>
      <li>Simple server, cheap to run</li>
      <li>Data flows peer-to-peer</li>
    </ul>
  </article>
   <aside class="note">
   <p>To solve this, we use a technology called STUN. If we tell WebRTC about the location of a STUN server, it can ask the STUN server to tell it the right public address to use. The STUN server's job is simple - it just looks at where an incoming request is coming from, and sends that address back in the response.  WebRTC can then exchange that public address with the other side and use that to set up a direct link.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>STUN</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/stun.png" alt="Data pathways between peers using STUN" style="position: relative; top: -50px">
  </article>
      <aside class="note">
      <p>Here's a diagram of that in action. Each side asks its STUN server what its public address is, and then the peers can directly connect. Now, this technique usually works, but depending on the kind of NAT or firewall that is present, there are some cases where it doesn't.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>TURN</h2>
  </hgroup>
  <article>
    <ul>
      <li>Provide a cloud fallback if peer-to-peer communication fails</li>
      <li>Data is sent through server, uses server bandwidth</li>
      <li>Ensures the call works in almost all environments</li>
    </ul>
  </article>
      <aside class="note">
      <p>The other technique that WebRTC can use is called TURN. A TURN server is essentially a server that relays the data an endpoint is trying to send to the other side. Because it has a public address already, it's easy to contact, so the connection always works, even in cases where the endpoint is behind a restrictive firewall or proxy. The downside is that all the data traffic has to go through the relay, so there's a nontrivial bandiwdth cost.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>TURN</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/STUNandTURN.png" alt="Data pathways between peers using TURN" style="left: 1px; position: relative; top: -47px">
  </article>
   <aside class="note">
      <p>Here's a diagram of that in action. We tried to use STUN, but it didn't quite work right. So instead, each side contacted its own TURN server, and then data flow goes from each endpoint, through the TURN server, to the other side.</p>
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/webrtc_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Security</h2>
  </hgroup>
  <aside class="note">
  <p>One question that comes up about WebRTC is how security is handled.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Security throughout WebRTC</h2>
  </hgroup>
  <article>
  <ul>
    <li>Mandatory encryption for media and data</li>
    <li>Secure UI, explicit opt-in</li>
    <li>Sandboxed, no plugins</li>
  </ul>
  </article>
<aside class="note">
    <p>We've taken care to build security into WebRTC from the very beginning; all media and data is encrypted and protected, we require opt-in from the user before enabling their mic and camera, and WebRTC runs in the Chrome sandbox, which means that even if someone sends malicious data to WebRTC, the browser will be unaffected.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Secure pathways</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/securePathways.png" alt="Secure pathways between peers" style="position: relative; top: -10px">
  </article>
  <aside class="note">
    <p>The only thing an app developer needs to do to ensure WebRTC security, is to use HTTPS when sending signaling data. In this diagram, the signaling pathways are protected using HTTPS, and the media and data are protected using the standard SRTP and DTLS mechanisms.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Resources</h2>
  </hgroup>
  <article>
  <ul>
    <li><a href="webrtc.org" title="WebRTC project website">webrtc.org</a></li>
    <li><a href="https://groups.google.com/forum/?fromgroups#!forum/discuss-webrtc" title="WebRTC discussion group">discuss-webrtc</a></li>
      <li><a href="https://twitter.com/webrtc" title="WebRTC on Twitter">@webrtc</a></li>
      <li>#media on irc.mozilla.org</li>
  </ul>
  </article>
<aside class="note">
    <p>webrtc.org has a blog, links to demos, documentation and links to code repositories</p>
    <p>...and follow Justin Uberti and Serge Lachapelle on Google+</p>
  </aside>
</slide>


  <slide class="thank-you-slide segue nobackground">
    <aside class="gdbar right"><img src="images/webrtc_icon_128.png"></aside>
    <article class="flexbox vleft auto-fadein">
      <h2>&lt;Thank You!&gt;</h2>
      <br><br>
      <ul>
        <li>Slides -  www.tarashish.com/webrtc-seminar</li>
        <li>Report -  www.tarashish.com/webrtc-seminar/report.pdf</li>
      </ul>
    </article>
  </slide>


  <slide class="backdrop"></slide>

</slides>


<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body>
</html>
